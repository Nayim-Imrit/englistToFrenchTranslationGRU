{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation(english_to_french)EncoderDecoderAndAccuracy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdN8opJ1pwUZqt/9x3p7U5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nayim-Imrit/englistToFrenchTranslationGRU/blob/main/Translation(english_to_french)EncoderDecoderAndAccuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import collections\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import Input, Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "from keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "WoZY93AaRHFE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        " \n",
        " \n",
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    Load dataset\n",
        "    \"\"\"\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = f.read()\n",
        " \n",
        "    return data.split('\\n')"
      ],
      "metadata": {
        "id": "EvSyB0MSRnye"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load English data\n",
        "english_sentences = load_data('/content/vocabs/small_vocab_en')\n",
        "# Load French data\n",
        "french_sentences = load_data('/content/vocabs/small_vocab_fr')\n",
        " \n",
        "print('Dataset Loaded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsO69mp4Ra3d",
        "outputId": "d418386e-53d5-4f14-f479-6b2c0372070a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sample_i in range(2):\n",
        "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
        "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH8tUu4GRqT1",
        "outputId": "150169e4-479a-4a70-e51b-9536cce6c974"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_vocab_en Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "small_vocab_fr Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "small_vocab_en Line 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
            "small_vocab_fr Line 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
        "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
        "\n",
        "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
        "print('{} unique English words.'.format(len(english_words_counter)))\n",
        "print('10 Most common words in the English dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
        "print('{} unique French words.'.format(len(french_words_counter)))\n",
        "print('10 Most common words in the French dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbwbU-p0RvZ5",
        "outputId": "ee3a4d08-522e-4dd5-c70a-950007f8d421"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1823250 English words.\n",
            "227 unique English words.\n",
            "10 Most common words in the English dataset:\n",
            "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
            "\n",
            "1961295 French words.\n",
            "355 unique French words.\n",
            "10 Most common words in the French dataset:\n",
            "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x):\n",
        "    \"\"\"\n",
        "    Tokenize x\n",
        "    :param x: List of sentences/strings to be tokenized\n",
        "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    tokenizer = Tokenizer(split=' ', char_level=False)\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    return tokenizer.texts_to_sequences(x), tokenizer           # texts_to_sequences_generator(), Yields individual sequences.\n",
        "\n",
        "# tests.test_tokenize(tokenize)\n",
        "\n",
        "# Tokenize Example output\n",
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',\n",
        "    'This is a short sentence .']\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(text_tokenizer.word_index)\n",
        "print()\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(sent))\n",
        "    print('  Output: {}'.format(token_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDJLpXy6R2yG",
        "outputId": "729f2895-dcf7-442f-faeb-b2bab863fd26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
            "\n",
            "Sequence 1 in x\n",
            "  Input:  The quick brown fox jumps over the lazy dog .\n",
            "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
            "Sequence 2 in x\n",
            "  Input:  By Jove , my quick study of lexicography won a prize .\n",
            "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
            "Sequence 3 in x\n",
            "  Input:  This is a short sentence .\n",
            "  Output: [18, 19, 3, 20, 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROnB2Af1Sihz",
        "outputId": "ba4367ab-aeab-4fb3-c1fb-767a747fd6ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 4, 5, 6, 7, 1, 8, 9],\n",
              " [10, 11, 12, 2, 13, 14, 15, 16, 3, 17],\n",
              " [18, 19, 3, 20, 21]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(x, length=None):\n",
        "    \"\"\"\n",
        "    Pad x\n",
        "    :param x: List of sequences.\n",
        "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
        "    :return: Padded numpy array of sequences\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    if length is None:\n",
        "        length = max([len(sentence) for sentence in x])\n",
        "    \n",
        "    return pad_sequences(x, maxlen=length, padding='post', truncating='post')\n",
        "\n",
        "# tests.test_pad(pad)\n",
        "\n",
        "# Pad Tokenized output\n",
        "test_pad = pad(text_tokenized)\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(np.array(token_sent)))\n",
        "    print('  Output: {}'.format(pad_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DptWj1qQSlvZ",
        "outputId": "76eb1e6a-1297-423b-d697-6f7d982d385c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence 1 in x\n",
            "  Input:  [1 2 4 5 6 7 1 8 9]\n",
            "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
            "Sequence 2 in x\n",
            "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
            "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
            "Sequence 3 in x\n",
            "  Input:  [18 19  3 20 21]\n",
            "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(x, y):\n",
        "    \"\"\"\n",
        "    Preprocess x and y\n",
        "    :param x: Feature List of sentences\n",
        "    :param y: Label List of sentences\n",
        "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
        "    \"\"\"\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
        "    preprocess(english_sentences, french_sentences)\n",
        "    \n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhuMha11Ss_R",
        "outputId": "e57f21e0-f298-48b6-932f-791591545d56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 15\n",
            "Max French sentence length: 21\n",
            "English vocabulary size: 199\n",
            "French vocabulary size: 344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(preproc_english_sentences))\n",
        "print(preproc_english_sentences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeE18TC7Sy1-",
        "outputId": "28b8c0ee-0a6f-4685-81ec-be14483a7452"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(137861, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Models\n",
        "\n",
        "In this section, experiment with various neural network architectures. You will begin by training four relatively simple architectures.\n",
        "\n",
        "    Model 1 is a simple RNN\n",
        "    Model 2 is a RNN with Embedding\n",
        "    Model 3 is a Bidirectional RNN\n",
        "    Model 4 is an optional Encoder-Decoder RNN\n",
        "    Model 5 is a custom RNN (a deeper architecture that is designed to outperform all four models)\n",
        "\n",
        "Ids Back to Text\n",
        "\n",
        "The neural network will be translating the input to words ids, which isn't the final form we want. We want the French translation. The function logits_to_text will bridge the gab between the logits from the neural network to the French translation. You'll be using this function to better understand the output of the neural network.\n"
      ],
      "metadata": {
        "id": "XOERIySMS42I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    \"\"\"\n",
        "    Turn logits from a neural network into text using the tokenizer\n",
        "    :param logits: Logits from a neural network\n",
        "    :param tokenizer: Keras Tokenizer fit on the labels\n",
        "    :return: String that represents the text of the logits\n",
        "    \"\"\"\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1) if index_to_words[prediction]!='<PAD>'] )\n",
        "\n",
        "print('`logits_to_text` function loaded.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVxGbESVS0aQ",
        "outputId": "e0749f16-0f9b-4c05-d9cf-33c0bc6a6046"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`logits_to_text` function loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A basic RNN model is a good baseline for sequence data. In this model, you'll build a RNN that translates English to French.\n",
        "Inputs/Outputs shape Basic RNN\n",
        "\n",
        "    LSTM or GRU Input shape (batchsize, timesteps, 1). The timesteps is the length of the input sequences (15 for en, 21 for fr)\n",
        "    output shape LSTM (batchsize, timesteps, num_units) because Return_sequence activated to return the output at each timestep\n",
        "    Use of TimeDistributed wrapper over Dense(unitsoutput=target_vocab_size) to process each timestep\n",
        "    for each time step, Dense outputs a probability distribution over target_vocab to predict next word\n"
      ],
      "metadata": {
        "id": "O3xQFmFVTGCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def token_to_words(sequence, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return [index_to_words[token] for token in sequence if index_to_words[token]!='<PAD>']"
      ],
      "metadata": {
        "id": "HwzwKNeHTFQF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a basic RNN on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # TODO: Build the layers\n",
        "    learning_rate = 0.001\n",
        "    english_input = Input(shape=input_shape[1:], name=\"input_layer\")    # the shape is (input length x 1) as batchsize excluded\n",
        "    \n",
        "    # LSTM takes as input (batchsize,input_length,1) and outputs (batchsize, input_length, 64) because return-seq=True\n",
        "    x = LSTM(64, return_sequences=True, activation=\"tanh\", name=\"LSTM_layer\")(english_input)\n",
        "    preds = TimeDistributed(Dense(french_vocab_size, activation=\"softmax\"), name=\"Dense_layer\")(x)\n",
        "    model = Model(inputs=english_input, outputs=preds, name='simple_LSTM')\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# tests.test_simple_model(simple_model)\n",
        "\n",
        "# Reshaping the input to work with a basic RNN\n",
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))  # reshape as 3D (batchsize, timesteps, 1) for LSTM input\n",
        "\n",
        "# Train the neural network\n",
        "simple_rnn_model = simple_model(\n",
        "    tmp_x.shape,\n",
        "    max_french_sequence_length,\n",
        "    english_vocab_size,\n",
        "    french_vocab_size)\n",
        "\n",
        "simple_rnn_model.summary()\n",
        "\n",
        "simple_rnn_model.fit(preproc_french_sentences, tmp_x, batch_size=1024, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL17qCSjTKoP",
        "outputId": "67fd5ad4-37a7-4d1d-9089-4a06a0c0cfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"simple_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 21, 1)]           0         \n",
            "                                                                 \n",
            " LSTM_layer (LSTM)           (None, 21, 64)            16896     \n",
            "                                                                 \n",
            " Dense_layer (TimeDistribute  (None, 21, 344)          22360     \n",
            " d)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,256\n",
            "Trainable params: 39,256\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "108/108 [==============================] - 40s 360ms/step - loss: 3.3054 - accuracy: 0.4432 - val_loss: 2.3822 - val_accuracy: 0.4783\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 38s 354ms/step - loss: 2.2534 - accuracy: 0.4971 - val_loss: 2.1263 - val_accuracy: 0.5081\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 39s 358ms/step - loss: 1.9989 - accuracy: 0.5375 - val_loss: 1.8741 - val_accuracy: 0.5649\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 38s 353ms/step - loss: 1.7808 - accuracy: 0.5819 - val_loss: 1.6843 - val_accuracy: 0.6012\n",
            "Epoch 5/20\n",
            "108/108 [==============================] - 38s 351ms/step - loss: 1.6012 - accuracy: 0.6241 - val_loss: 1.5182 - val_accuracy: 0.6473\n",
            "Epoch 6/20\n",
            "108/108 [==============================] - 38s 353ms/step - loss: 1.4488 - accuracy: 0.6582 - val_loss: 1.3767 - val_accuracy: 0.6687\n",
            "Epoch 7/20\n",
            "108/108 [==============================] - 38s 349ms/step - loss: 1.3135 - accuracy: 0.6790 - val_loss: 1.2548 - val_accuracy: 0.6885\n",
            "Epoch 8/20\n",
            "108/108 [==============================] - 38s 351ms/step - loss: 1.2085 - accuracy: 0.6943 - val_loss: 1.1655 - val_accuracy: 0.7019\n",
            "Epoch 9/20\n",
            "108/108 [==============================] - 38s 350ms/step - loss: 1.1267 - accuracy: 0.7086 - val_loss: 1.0902 - val_accuracy: 0.7149\n",
            "Epoch 10/20\n",
            "108/108 [==============================] - 38s 352ms/step - loss: 1.0586 - accuracy: 0.7181 - val_loss: 1.0308 - val_accuracy: 0.7164\n",
            "Epoch 11/20\n",
            "108/108 [==============================] - 38s 355ms/step - loss: 1.0043 - accuracy: 0.7243 - val_loss: 0.9826 - val_accuracy: 0.7250\n",
            "Epoch 12/20\n",
            "108/108 [==============================] - 38s 352ms/step - loss: 0.9616 - accuracy: 0.7334 - val_loss: 0.9437 - val_accuracy: 0.7344\n",
            "Epoch 13/20\n",
            "108/108 [==============================] - 38s 349ms/step - loss: 0.9259 - accuracy: 0.7444 - val_loss: 0.9123 - val_accuracy: 0.7511\n",
            "Epoch 14/20\n",
            "108/108 [==============================] - 38s 350ms/step - loss: 0.8947 - accuracy: 0.7526 - val_loss: 0.8825 - val_accuracy: 0.7570\n",
            "Epoch 15/20\n",
            "108/108 [==============================] - 38s 349ms/step - loss: 0.8675 - accuracy: 0.7563 - val_loss: 0.8566 - val_accuracy: 0.7620\n",
            "Epoch 16/20\n",
            "108/108 [==============================] - 38s 348ms/step - loss: 0.8429 - accuracy: 0.7613 - val_loss: 0.8335 - val_accuracy: 0.7617\n",
            "Epoch 17/20\n",
            "108/108 [==============================] - 38s 351ms/step - loss: 0.8211 - accuracy: 0.7656 - val_loss: 0.8128 - val_accuracy: 0.7679\n",
            "Epoch 18/20\n",
            "108/108 [==============================] - 38s 350ms/step - loss: 0.8013 - accuracy: 0.7696 - val_loss: 0.7946 - val_accuracy: 0.7714\n",
            "Epoch 19/20\n",
            "108/108 [==============================] - 38s 356ms/step - loss: 0.7833 - accuracy: 0.7722 - val_loss: 0.7777 - val_accuracy: 0.7727\n",
            "Epoch 20/20\n",
            "108/108 [==============================] - 38s 354ms/step - loss: 0.7667 - accuracy: 0.7750 - val_loss: 0.7622 - val_accuracy: 0.7743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc68f45de90>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(prediction, gold_standard):\n",
        "    \n",
        "    translation = logits_to_text(prediction[0], french_tokenizer)\n",
        "    standard = ' '.join(token_to_words(gold_standard[0][:,0],french_tokenizer)) \n",
        "    print('---- Gold standard ----')\n",
        "    print(standard)\n",
        "    print()\n",
        "    print('---- Prediction ----')\n",
        "    for w_t, w_s in zip(translation.split(), standard.split()):\n",
        "        if w_t == w_s:\n",
        "            print('\\033[0;30;0m','{}'.format(w_t), end='')\n",
        "        else:\n",
        "            print('\\033[0;31;47m', w_t, end='')\n",
        "    print()"
      ],
      "metadata": {
        "id": "GaWW3i5uZkXj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print('---- Original ----')\n",
        "print(' '.join(token_to_words(tmp_x[:1][0][:,0],english_tokenizer) ))\n",
        "print()\n",
        "translate(simple_rnn_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhJMQoE_Zmc9",
        "outputId": "2ffad1c2-a395-4e23-c406-c8afa7ced5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Original ----\n",
            "new jersey is sometimes quiet during autumn and it is snowy in april\n",
            "\n",
            "---- Gold standard ----\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
            "\n",
            "---- Prediction ----\n",
            "\u001b[0;31;47m froid\u001b[0;31;47m est\u001b[0;30;0m est\u001b[0;31;47m les\u001b[0;31;47m les\u001b[0;31;47m et\u001b[0;31;47m il\u001b[0;31;47m est\u001b[0;31;47m le\u001b[0;31;47m en\u001b[0;31;47m en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: Embedding (IMPLEMENTATION)\n",
        "there's a better representation of a word. This is called word embeddings. An embedding is a vector representation of the word that is close to similar words in n-dimensional space, where the n represents the size of the embedding vectors.\n",
        "\n",
        "In this model, we create a RNN model using embedding.\n",
        "Inputs/Outputs shape embedding RNN\n",
        "\n",
        "    Input shape to Embedding layer (batchsize, input_length ie timesteps). the timesteps = length of the sequences\n",
        "    Input to the Embedding layer is vector of vocab_size for each token, converted into vector of embed_dim size\n",
        "    Embeddings output_shape is (None, sequence_length, embbed_dim). This is 3D expected by LSTM !\n",
        "    output shape LSTM (None, timesteps = sequence_length, num_units). Return_sequence activated to return output at each timestep\n",
        "    Use of TimeDistributed wrapper over Dense(target_vocab_size) to process each timestep\n",
        "    for each time step, Dense outputs a probability distribution over target_vocab to predict next word\n",
        "\n"
      ],
      "metadata": {
        "id": "MvX0lfwSZtZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a RNN model using word embedding on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    \n",
        "    learning_rate = 0.001\n",
        "    embedding_size = 256\n",
        "    \n",
        "    english_input = Input(shape=input_shape[1:], name=\"input_layer\")   # Input shape (,seq_length)\n",
        "    \n",
        "    embeddings = Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
        "                           input_length= output_sequence_length, name=\"Embedding_layer\")(english_input)\n",
        "    \n",
        "    x = LSTM(64, return_sequences=True, activation=\"tanh\", name=\"LSTM_layer\")(embeddings)\n",
        "    \n",
        "    preds = TimeDistributed(Dense(french_vocab_size, activation=\"softmax\"), name=\"Dense_layer\")(x)\n",
        "    \n",
        "    model = Model(inputs=english_input, outputs=preds, name='Embedding_LSTM')\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "#tests.test_embed_model(embed_model)\n",
        "\n",
        "# TODO: Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))    # reshaped to (batchsize, seq_length) for Embedding input\n",
        "\n",
        "# Train the neural network\n",
        "embed_rnn_model = embed_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "embed_rnn_model.summary()\n",
        "\n",
        "embed_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLzkZmUQZzF0",
        "outputId": "0e2d536f-e606-4b5d-cb15-42e1e5d34c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Embedding_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 21)]              0         \n",
            "                                                                 \n",
            " Embedding_layer (Embedding)  (None, 21, 256)          51200     \n",
            "                                                                 \n",
            " LSTM_layer (LSTM)           (None, 21, 64)            82176     \n",
            "                                                                 \n",
            " Dense_layer (TimeDistribute  (None, 21, 345)          22425     \n",
            " d)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 155,801\n",
            "Trainable params: 155,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "108/108 [==============================] - 61s 550ms/step - loss: 3.5659 - accuracy: 0.4065 - val_loss: 2.7441 - val_accuracy: 0.4110\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 58s 534ms/step - loss: 2.4236 - accuracy: 0.4873 - val_loss: 2.0589 - val_accuracy: 0.5303\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 57s 532ms/step - loss: 1.7720 - accuracy: 0.5847 - val_loss: 1.5064 - val_accuracy: 0.6339\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 57s 529ms/step - loss: 1.2967 - accuracy: 0.6830 - val_loss: 1.1115 - val_accuracy: 0.7311\n",
            "Epoch 5/20\n",
            "108/108 [==============================] - 56s 523ms/step - loss: 0.9890 - accuracy: 0.7523 - val_loss: 0.8861 - val_accuracy: 0.7706\n",
            "Epoch 6/20\n",
            "108/108 [==============================] - 56s 520ms/step - loss: 0.8193 - accuracy: 0.7815 - val_loss: 0.7577 - val_accuracy: 0.7938\n",
            "Epoch 7/20\n",
            "108/108 [==============================] - 56s 518ms/step - loss: 0.7158 - accuracy: 0.8022 - val_loss: 0.6736 - val_accuracy: 0.8099\n",
            "Epoch 8/20\n",
            "108/108 [==============================] - 56s 518ms/step - loss: 0.6437 - accuracy: 0.8164 - val_loss: 0.6127 - val_accuracy: 0.8221\n",
            "Epoch 9/20\n",
            "108/108 [==============================] - 56s 516ms/step - loss: 0.5901 - accuracy: 0.8293 - val_loss: 0.5658 - val_accuracy: 0.8358\n",
            "Epoch 10/20\n",
            "108/108 [==============================] - 56s 515ms/step - loss: 0.5487 - accuracy: 0.8396 - val_loss: 0.5299 - val_accuracy: 0.8450\n",
            "Epoch 11/20\n",
            "108/108 [==============================] - 56s 518ms/step - loss: 0.5140 - accuracy: 0.8487 - val_loss: 0.4990 - val_accuracy: 0.8520\n",
            "Epoch 12/20\n",
            "108/108 [==============================] - 56s 518ms/step - loss: 0.4859 - accuracy: 0.8563 - val_loss: 0.4712 - val_accuracy: 0.8603\n",
            "Epoch 13/20\n",
            "108/108 [==============================] - 56s 518ms/step - loss: 0.4621 - accuracy: 0.8624 - val_loss: 0.4504 - val_accuracy: 0.8646\n",
            "Epoch 14/20\n",
            "108/108 [==============================] - 56s 523ms/step - loss: 0.4405 - accuracy: 0.8679 - val_loss: 0.4302 - val_accuracy: 0.8698\n",
            "Epoch 15/20\n",
            "108/108 [==============================] - 57s 527ms/step - loss: 0.4200 - accuracy: 0.8737 - val_loss: 0.4114 - val_accuracy: 0.8760\n",
            "Epoch 16/20\n",
            "108/108 [==============================] - 57s 524ms/step - loss: 0.4040 - accuracy: 0.8780 - val_loss: 0.3968 - val_accuracy: 0.8797\n",
            "Epoch 17/20\n",
            "108/108 [==============================] - 56s 522ms/step - loss: 0.3885 - accuracy: 0.8825 - val_loss: 0.3889 - val_accuracy: 0.8818\n",
            "Epoch 18/20\n",
            "108/108 [==============================] - 56s 519ms/step - loss: 0.3750 - accuracy: 0.8863 - val_loss: 0.3705 - val_accuracy: 0.8860\n",
            "Epoch 19/20\n",
            "108/108 [==============================] - 56s 517ms/step - loss: 0.3626 - accuracy: 0.8898 - val_loss: 0.3608 - val_accuracy: 0.8902\n",
            "Epoch 20/20\n",
            "108/108 [==============================] - 56s 517ms/step - loss: 0.3513 - accuracy: 0.8933 - val_loss: 0.3474 - val_accuracy: 0.8948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc682ac36d0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print('---- Original ----')\n",
        "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n",
        "print()\n",
        "translate(embed_rnn_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwQEFLFQjJ1T",
        "outputId": "1cf2d655-d4b3-41ab-fef4-ffdcd6a6de00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Original ----\n",
            "new jersey is sometimes quiet during autumn and it is snowy in april\n",
            "\n",
            "---- Gold standard ----\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
            "\n",
            "---- Prediction ----\n",
            "\u001b[0;30;0m new\u001b[0;30;0m jersey\u001b[0;30;0m est\u001b[0;30;0m parfois\u001b[0;30;0m calme\u001b[0;31;47m au\u001b[0;30;0m l'\u001b[0;31;47m et\u001b[0;31;47m il\u001b[0;31;47m et\u001b[0;30;0m est\u001b[0;31;47m est\u001b[0;30;0m en\u001b[0;31;47m en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: Bidirectional RNNs (IMPLEMENTATION)\n",
        "One restriction of a RNN is that it can't see the future input, only the past. This is where bidirectional recurrent neural networks come in. They are able to see the future data.\n",
        "Inputs/Outputs shape Bidirectional RNN\n",
        "\n",
        "    LSTM or GRU Input shape (batchsize, timesteps, 1). The timesteps is the length of the input sequences (15 for en, 21 for fr)\n",
        "    output shape Bidir-LSTM (None, timesteps = sequence_length, 2 x num_units) because both outputs are concatenated.\n",
        "    Return_sequence activated to return output at each timestep\n",
        "    Use of TimeDistributed wrapper over Dense(target_vocab_size) to process each timestep\n",
        "    for each time step, Dense outputs a probability distribution over target_vocab to predict next word\n",
        "\n"
      ],
      "metadata": {
        "id": "2fHs7QK7jUS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a bidirectional RNN model on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    \n",
        "    learning_rate = 0.001\n",
        "    embedding_size = 256\n",
        "    \n",
        "    english_input = Input(shape=input_shape[1:], name=\"input_layer\")  # input to LSTM shape (batch, seq_length, 1)\n",
        "    \n",
        "    x = Bidirectional(LSTM(64, return_sequences=True, activation=\"tanh\", name=\"Bidir_LSTM_layer\"), input_shape=input_shape[1:])(english_input)\n",
        "    \n",
        "    preds = TimeDistributed(Dense(french_vocab_size, activation=\"softmax\"), name=\"Dense_layer\")(x)\n",
        "    \n",
        "    model = Model(inputs=english_input, outputs=preds, name='Bidir_LSTM')\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "#tests.test_bd_model(bd_model)\n",
        "\n",
        "# TODO: Train and Print prediction(s)\n",
        "\n",
        "# TODO: Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2],1))  # reshape to (batch, seq_length, 1) for LSTM input\n",
        "\n",
        "# Train the neural network\n",
        "bd_rnn_model = bd_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "bd_rnn_model.summary()\n",
        "    \n",
        "bd_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FMu8V9LjXw3",
        "outputId": "6bbfd732-f9ca-467e-e16d-7e582320fe7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Bidir_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 21, 1)]           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 21, 128)          33792     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " Dense_layer (TimeDistribute  (None, 21, 345)          44505     \n",
            " d)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 78,297\n",
            "Trainable params: 78,297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "108/108 [==============================] - 59s 522ms/step - loss: 3.2280 - accuracy: 0.4417 - val_loss: 2.2363 - val_accuracy: 0.4857\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 55s 514ms/step - loss: 2.0175 - accuracy: 0.5249 - val_loss: 1.8127 - val_accuracy: 0.5692\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 55s 509ms/step - loss: 1.6948 - accuracy: 0.5808 - val_loss: 1.6014 - val_accuracy: 0.5968\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 55s 507ms/step - loss: 1.5419 - accuracy: 0.6046 - val_loss: 1.4894 - val_accuracy: 0.6135\n",
            "Epoch 5/20\n",
            "108/108 [==============================] - 54s 505ms/step - loss: 1.4509 - accuracy: 0.6149 - val_loss: 1.4137 - val_accuracy: 0.6203\n",
            "Epoch 6/20\n",
            "108/108 [==============================] - 55s 508ms/step - loss: 1.3847 - accuracy: 0.6238 - val_loss: 1.3564 - val_accuracy: 0.6280\n",
            "Epoch 7/20\n",
            "108/108 [==============================] - 55s 510ms/step - loss: 1.3334 - accuracy: 0.6318 - val_loss: 1.3108 - val_accuracy: 0.6349\n",
            "Epoch 8/20\n",
            "108/108 [==============================] - 55s 512ms/step - loss: 1.2934 - accuracy: 0.6387 - val_loss: 1.2750 - val_accuracy: 0.6416\n",
            "Epoch 9/20\n",
            "108/108 [==============================] - 55s 510ms/step - loss: 1.2598 - accuracy: 0.6457 - val_loss: 1.2441 - val_accuracy: 0.6500\n",
            "Epoch 10/20\n",
            "108/108 [==============================] - 55s 513ms/step - loss: 1.2314 - accuracy: 0.6517 - val_loss: 1.2185 - val_accuracy: 0.6526\n",
            "Epoch 11/20\n",
            "108/108 [==============================] - 55s 510ms/step - loss: 1.2068 - accuracy: 0.6559 - val_loss: 1.1943 - val_accuracy: 0.6571\n",
            "Epoch 12/20\n",
            "108/108 [==============================] - 55s 512ms/step - loss: 1.1842 - accuracy: 0.6600 - val_loss: 1.1732 - val_accuracy: 0.6603\n",
            "Epoch 13/20\n",
            "108/108 [==============================] - 55s 510ms/step - loss: 1.1628 - accuracy: 0.6640 - val_loss: 1.1518 - val_accuracy: 0.6643\n",
            "Epoch 14/20\n",
            "108/108 [==============================] - 55s 514ms/step - loss: 1.1433 - accuracy: 0.6670 - val_loss: 1.1337 - val_accuracy: 0.6686\n",
            "Epoch 15/20\n",
            "108/108 [==============================] - 55s 509ms/step - loss: 1.1260 - accuracy: 0.6705 - val_loss: 1.1175 - val_accuracy: 0.6712\n",
            "Epoch 16/20\n",
            "108/108 [==============================] - 55s 506ms/step - loss: 1.1109 - accuracy: 0.6731 - val_loss: 1.1029 - val_accuracy: 0.6758\n",
            "Epoch 17/20\n",
            "108/108 [==============================] - 54s 503ms/step - loss: 1.0970 - accuracy: 0.6757 - val_loss: 1.0909 - val_accuracy: 0.6759\n",
            "Epoch 18/20\n",
            "108/108 [==============================] - 54s 505ms/step - loss: 1.0844 - accuracy: 0.6777 - val_loss: 1.0785 - val_accuracy: 0.6793\n",
            "Epoch 19/20\n",
            "108/108 [==============================] - 54s 504ms/step - loss: 1.0729 - accuracy: 0.6800 - val_loss: 1.0670 - val_accuracy: 0.6801\n",
            "Epoch 20/20\n",
            "108/108 [==============================] - 54s 504ms/step - loss: 1.0615 - accuracy: 0.6823 - val_loss: 1.0565 - val_accuracy: 0.6847\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc68ee89950>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print('---- Original ----')\n",
        "print(' '.join(token_to_words(tmp_x[:1][0][:,0],english_tokenizer) ))\n",
        "print()\n",
        "translate(bd_rnn_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4pxdaAyoTTt",
        "outputId": "ee69e328-c26d-4bf0-b74a-b19e4027a9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Original ----\n",
            "new jersey is sometimes quiet during autumn and it is snowy in april\n",
            "\n",
            "---- Gold standard ----\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
            "\n",
            "---- Prediction ----\n",
            "\u001b[0;30;0m new\u001b[0;30;0m jersey\u001b[0;30;0m est\u001b[0;30;0m parfois\u001b[0;30;0m calme\u001b[0;31;47m en\u001b[0;31;47m mois\u001b[0;31;47m et\u001b[0;31;47m il\u001b[0;31;47m est\u001b[0;30;0m est\u001b[0;31;47m est\u001b[0;30;0m en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Model 3 bis: Embedding Bidirectional RNNs (IMPLEMENTATION)\n",
        "Inputs/Outputs shape Embedding Bidirectional RNN\n",
        "\n",
        "    Embedding requires input shape (batchsize, input_length) and outputs (batchsize, input_length, embedded_dim)\n",
        "    this shape is OK for input to LSTM (3D)\n",
        "    LSTM or GRU Input shape (batchsize, timesteps, embedded_dim). Return_sequence activated to return output at each timestep\n",
        "    output shape Bidir-LSTM (None, timesteps = sequence_length, 2 x LSTM num_units) because both outputs are concatenated.\n",
        "    Use of TimeDistributed wrapper over Dense(target_vocab_size) to process each timestep\n",
        "    for each time step, Dense outputs a probability distribution over target_vocab to predict next word\n",
        "\n"
      ],
      "metadata": {
        "id": "RokiRbd7sb3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def emb_bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a bidirectional RNN model on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    \n",
        "    learning_rate = 0.001\n",
        "    embedding_size = 256\n",
        "    \n",
        "    english_input = Input(shape=input_shape[1:], name=\"input_layer\")  # Embedding input (batch, seq_length)\n",
        "    \n",
        "    embeddings = Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
        "                           input_length= output_sequence_length, name=\"Embedding_layer\")(english_input)\n",
        "    \n",
        "    # input shape to LSTM (batchsize, seq_length, embedding_dim) output shape: (batchsize, seq_length, units=64x2)\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True, activation=\"tanh\"), name=\"Bidir_LSTM_layer\")(embeddings)\n",
        "    \n",
        "    preds = TimeDistributed(Dense(french_vocab_size, activation=\"softmax\"), name=\"Dense_layer\")(x)\n",
        "    \n",
        "    model = Model(inputs=english_input, outputs=preds, name='Embedding_Bidir_LSTM')\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "   \n",
        "    return model\n",
        "\n",
        "#tests.test_bd_model(bd_model)\n",
        "\n",
        "# TODO: Train and Print prediction(s)\n",
        "\n",
        "# TODO: Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))    # reshapped for Embedding input (batch, seq_length)\n",
        "\n",
        "# Train the neural network\n",
        "emb_bd_rnn_model = emb_bd_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "emb_bd_rnn_model.summary()\n",
        "\n",
        "emb_bd_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i7bEs0Ksa_n",
        "outputId": "412915ba-65f4-4b64-ea06-404cc2f53346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Embedding_Bidir_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 21)]              0         \n",
            "                                                                 \n",
            " Embedding_layer (Embedding)  (None, 21, 256)          51200     \n",
            "                                                                 \n",
            " Bidir_LSTM_layer (Bidirecti  (None, 21, 128)          164352    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " Dense_layer (TimeDistribute  (None, 21, 345)          44505     \n",
            " d)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 260,057\n",
            "Trainable params: 260,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "108/108 [==============================] - 99s 852ms/step - loss: 3.1375 - accuracy: 0.4486 - val_loss: 2.3398 - val_accuracy: 0.4962\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 90s 835ms/step - loss: 1.9899 - accuracy: 0.5398 - val_loss: 1.6701 - val_accuracy: 0.6010\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 89s 823ms/step - loss: 1.3941 - accuracy: 0.6529 - val_loss: 1.1415 - val_accuracy: 0.7059\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 91s 843ms/step - loss: 0.9766 - accuracy: 0.7408 - val_loss: 0.8414 - val_accuracy: 0.7673\n",
            "Epoch 5/20\n",
            "108/108 [==============================] - 93s 865ms/step - loss: 0.7585 - accuracy: 0.7858 - val_loss: 0.6856 - val_accuracy: 0.8041\n",
            "Epoch 6/20\n",
            "108/108 [==============================] - 91s 846ms/step - loss: 0.6366 - accuracy: 0.8151 - val_loss: 0.5893 - val_accuracy: 0.8287\n",
            "Epoch 7/20\n",
            "108/108 [==============================] - 91s 839ms/step - loss: 0.5543 - accuracy: 0.8375 - val_loss: 0.5187 - val_accuracy: 0.8475\n",
            "Epoch 8/20\n",
            "108/108 [==============================] - 90s 838ms/step - loss: 0.4931 - accuracy: 0.8557 - val_loss: 0.4681 - val_accuracy: 0.8633\n",
            "Epoch 9/20\n",
            "108/108 [==============================] - 91s 840ms/step - loss: 0.4486 - accuracy: 0.8682 - val_loss: 0.4289 - val_accuracy: 0.8743\n",
            "Epoch 10/20\n",
            "108/108 [==============================] - 90s 834ms/step - loss: 0.4116 - accuracy: 0.8792 - val_loss: 0.3965 - val_accuracy: 0.8830\n",
            "Epoch 11/20\n",
            "108/108 [==============================] - 91s 842ms/step - loss: 0.3810 - accuracy: 0.8880 - val_loss: 0.3691 - val_accuracy: 0.8919\n",
            "Epoch 12/20\n",
            "108/108 [==============================] - 90s 835ms/step - loss: 0.3575 - accuracy: 0.8943 - val_loss: 0.3485 - val_accuracy: 0.8968\n",
            "Epoch 13/20\n",
            "108/108 [==============================] - 90s 836ms/step - loss: 0.3363 - accuracy: 0.9005 - val_loss: 0.3310 - val_accuracy: 0.9019\n",
            "Epoch 14/20\n",
            "108/108 [==============================] - 89s 828ms/step - loss: 0.3174 - accuracy: 0.9065 - val_loss: 0.3135 - val_accuracy: 0.9081\n",
            "Epoch 15/20\n",
            "108/108 [==============================] - 89s 822ms/step - loss: 0.3009 - accuracy: 0.9119 - val_loss: 0.2956 - val_accuracy: 0.9140\n",
            "Epoch 16/20\n",
            "108/108 [==============================] - 89s 823ms/step - loss: 0.2853 - accuracy: 0.9168 - val_loss: 0.2825 - val_accuracy: 0.9178\n",
            "Epoch 17/20\n",
            "108/108 [==============================] - 89s 820ms/step - loss: 0.2721 - accuracy: 0.9206 - val_loss: 0.2702 - val_accuracy: 0.9203\n",
            "Epoch 18/20\n",
            "108/108 [==============================] - 88s 813ms/step - loss: 0.2586 - accuracy: 0.9250 - val_loss: 0.2566 - val_accuracy: 0.9260\n",
            "Epoch 19/20\n",
            "108/108 [==============================] - 88s 811ms/step - loss: 0.2475 - accuracy: 0.9282 - val_loss: 0.2471 - val_accuracy: 0.9287\n",
            "Epoch 20/20\n",
            "108/108 [==============================] - 88s 812ms/step - loss: 0.2360 - accuracy: 0.9323 - val_loss: 0.2363 - val_accuracy: 0.9319\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc68444aa90>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print('---- Original ----')\n",
        "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n",
        "print()\n",
        "translate(emb_bd_rnn_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M82lYkcX0Mp8",
        "outputId": "4f203000-3aff-49c5-918d-b2284f9f87f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Original ----\n",
            "new jersey is sometimes quiet during autumn and it is snowy in april\n",
            "\n",
            "---- Gold standard ----\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
            "\n",
            "---- Prediction ----\n",
            "\u001b[0;30;0m new\u001b[0;30;0m jersey\u001b[0;30;0m est\u001b[0;30;0m parfois\u001b[0;30;0m calme\u001b[0;30;0m pendant\u001b[0;30;0m l'\u001b[0;31;47m et\u001b[0;31;47m il\u001b[0;30;0m il\u001b[0;30;0m est\u001b[0;30;0m neigeux\u001b[0;30;0m en\u001b[0;30;0m avril\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4: Encoder-Decoder\n",
        " This model is made up of an encoder and decoder. The encoder creates a matrix representation of the sentence. The decoder takes this matrix as input and predicts the translation as output.\n",
        "\n",
        "\n",
        "    Encoder: One or more LSTM layers can be used to implement the encoder model. The output of this model is a fixed-size vector that represents the internal representation of the input sequence. The number of memory cells in this layer defines the length of this fixed-sized vector.\n",
        "\n",
        "    Decoder: The decoder must transform the learned internal representation of the input sequence into the correct output sequence. One or more LSTM layers can also be used to implement the decoder model. This model reads from the fixed sized output from the encoder model.\n",
        "\n",
        "Issue: We must connect the encoder to the decoder, and they do not fit. That is, the encoder will produce a 2-dimensional matrix of outputs, where the length is defined by the number of memory cells in the layer. The decoder is an LSTM layer that expects a 3D input of [samples, time steps, features] in order to produce a decoded sequence of some different length defined by the problem.\n",
        "\n",
        "We can solve this using a RepeatVector layer. This layer simply repeats the provided 2D input multiple times to create a 3D output. The RepeatVector layer can be used like an adapter to fit the encoder and decoder parts of the network together. We can configure the RepeatVector to repeat the fixed length vector one time for each time step in the output sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "d3rJm_R-0ShF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encdec_model2(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train an encoder-decoder model on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # OPTIONAL: Implement\n",
        "    \n",
        "    learning_rate = 0.001\n",
        "    embedding_size = 300\n",
        "    num_units = 256\n",
        "    \n",
        "    ########### ENCODER ###########\n",
        "    encoder_input = Input(shape=input_shape[1:], name=\"input_Encoder\")\n",
        "    \n",
        "    embeddings = Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
        "                           input_length= input_shape[1], name=\"Embedding_layer\")(encoder_input)\n",
        "    \n",
        "    encoder_output = Bidirectional(LSTM(num_units, return_sequences=False, activation=\"relu\"), name=\"Bidir_Encoder\")(embeddings)\n",
        "    # output shape of decoder = (batch , num_units)\n",
        "    \n",
        "    ########### INTERMEDIARY ###########\n",
        "    # This adjusts the shape of the Encoder output (2D) to the need of the Decoder (3D input).\n",
        "    # We repeat the 2D vector over sequence_length times to produce the shape (batchsize, seq_length, LSTM units)\n",
        "    input_decoder = RepeatVector(output_sequence_length)(encoder_output)\n",
        "    \n",
        "    ########### DECODER ###########\n",
        "    decoder_input = Input(shape=input_decoder.shape[:1], name=\"input_Decoder\")\n",
        "    \n",
        "    x = LSTM(num_units, return_sequences=True, activation=\"relu\", name=\"LSTM_layer1\")(input_decoder)\n",
        "    x = LSTM(num_units, return_sequences=True, activation=\"relu\", name=\"LSTM_layer2\")(x)\n",
        "    \n",
        "    preds = TimeDistributed(Dense(french_vocab_size, activation=\"softmax\"), name=\"Dense_layer\")(x)\n",
        "\n",
        "    ########### END-TO-END MODEL ###########\n",
        "    model = Model(inputs=encoder_input, outputs=preds, name='Encdec')\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "#tests.test_encdec_model(encdec_model2) # commented out to avoid error: english sequences padded to french sequence max length\n",
        "\n",
        "# OPTIONAL: Train and Print prediction(s)\n",
        "\n",
        "# TODO: Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))   # reshape for embedding input\n",
        "\n",
        "# Train the neural network\n",
        "enc_dec_model2 = encdec_model2(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "enc_dec_model2.summary()\n",
        "\n",
        "enc_dec_model2.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=15, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfzyu2i60h-M",
        "outputId": "ca79055b-2282-44a7-8e94-9bc6f6e9914c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Encdec\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_Encoder (InputLayer)  [(None, 21)]              0         \n",
            "                                                                 \n",
            " Embedding_layer (Embedding)  (None, 21, 300)          60000     \n",
            "                                                                 \n",
            " Bidir_Encoder (Bidirectiona  (None, 512)              1140736   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 21, 512)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " LSTM_layer1 (LSTM)          (None, 21, 256)           787456    \n",
            "                                                                 \n",
            " LSTM_layer2 (LSTM)          (None, 21, 256)           525312    \n",
            "                                                                 \n",
            " Dense_layer (TimeDistribute  (None, 21, 345)          88665     \n",
            " d)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,602,169\n",
            "Trainable params: 2,602,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "108/108 [==============================] - 685s 6s/step - loss: 2.8764 - accuracy: 0.4613 - val_loss: 2.1275 - val_accuracy: 0.5305\n",
            "Epoch 2/15\n",
            "108/108 [==============================] - 681s 6s/step - loss: 1.6780 - accuracy: 0.5729 - val_loss: 1.3605 - val_accuracy: 0.6155\n",
            "Epoch 3/15\n",
            "108/108 [==============================] - 679s 6s/step - loss: 1.2424 - accuracy: 0.6410 - val_loss: 1.0525 - val_accuracy: 0.6864\n",
            "Epoch 4/15\n",
            "108/108 [==============================] - 677s 6s/step - loss: 0.9641 - accuracy: 0.7072 - val_loss: 0.8772 - val_accuracy: 0.7325\n",
            "Epoch 5/15\n",
            "108/108 [==============================] - 677s 6s/step - loss: 0.8025 - accuracy: 0.7512 - val_loss: 0.7176 - val_accuracy: 0.7749\n",
            "Epoch 6/15\n",
            "108/108 [==============================] - 678s 6s/step - loss: 0.6531 - accuracy: 0.7903 - val_loss: 0.5902 - val_accuracy: 0.8076\n",
            "Epoch 7/15\n",
            "108/108 [==============================] - 677s 6s/step - loss: 0.5438 - accuracy: 0.8222 - val_loss: 0.4754 - val_accuracy: 0.8451\n",
            "Epoch 8/15\n",
            "108/108 [==============================] - 677s 6s/step - loss: 0.4427 - accuracy: 0.8541 - val_loss: 0.3969 - val_accuracy: 0.8719\n",
            "Epoch 9/15\n",
            "108/108 [==============================] - 680s 6s/step - loss: 0.3449 - accuracy: 0.8869 - val_loss: 0.3167 - val_accuracy: 0.8981\n",
            "Epoch 10/15\n",
            "108/108 [==============================] - 678s 6s/step - loss: 0.4597 - accuracy: 0.8591 - val_loss: 0.3072 - val_accuracy: 0.9007\n",
            "Epoch 11/15\n",
            "108/108 [==============================] - 676s 6s/step - loss: 0.2583 - accuracy: 0.9168 - val_loss: 0.2360 - val_accuracy: 0.9248\n",
            "Epoch 12/15\n",
            "108/108 [==============================] - 677s 6s/step - loss: 0.2171 - accuracy: 0.9308 - val_loss: 0.3174 - val_accuracy: 0.8961\n",
            "Epoch 13/15\n",
            "108/108 [==============================] - 677s 6s/step - loss: 0.1890 - accuracy: 0.9403 - val_loss: 0.1677 - val_accuracy: 0.9481\n",
            "Epoch 14/15\n",
            "108/108 [==============================] - 677s 6s/step - loss: 0.1489 - accuracy: 0.9531 - val_loss: 0.1756 - val_accuracy: 0.9470\n",
            "Epoch 15/15\n",
            "108/108 [==============================] - 679s 6s/step - loss: 0.1347 - accuracy: 0.9578 - val_loss: 0.1345 - val_accuracy: 0.9589\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa72f943650>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('---- Original ----')\n",
        "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n",
        "print()\n",
        "translate(enc_dec_model2.predict(tmp_x[:1]), preproc_french_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDe-cBzsqt8V",
        "outputId": "f6081957-38e7-49ec-e847-7d6ad6370a1d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Original ----\n",
            "new jersey is sometimes quiet during autumn and it is snowy in april\n",
            "\n",
            "---- Gold standard ----\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
            "\n",
            "---- Prediction ----\n",
            "\u001b[0;30;0m new\u001b[0;30;0m jersey\u001b[0;30;0m est\u001b[0;30;0m parfois\u001b[0;30;0m calme\u001b[0;30;0m pendant\u001b[0;30;0m l'\u001b[0;31;47m et\u001b[0;30;0m et\u001b[0;30;0m il\u001b[0;31;47m neigeux\u001b[0;30;0m neigeux\u001b[0;30;0m en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Encoder Decoder model with GRU RNN\n",
        "\n",
        "    No bidirectional unit\n",
        "    1 layer depth for both encoder and decoder\n",
        "    Much less parameters compared to LSTM\n",
        "\n"
      ],
      "metadata": {
        "id": "dTDz-4J9rniZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encdec_model4(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train an encoder-decoder model on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # OPTIONAL: Implement\n",
        "    \n",
        "    learning_rate = 0.001\n",
        "    embedding_size = 256\n",
        "    num_units = 256\n",
        "    \n",
        "    model = Sequential(name='enc_dec_model4')\n",
        "    \n",
        "    ########### ENCODER ###########\n",
        "    # Embedding layer - Input shape (batch_size, seq_length)\n",
        "    model.add(Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
        "                           input_length= input_shape[1], name=\"Embedding_layer\"))\n",
        "    \n",
        "    # Expected shape for GRU layer input : (batchsize, Seq_length, embedding_size)\n",
        "    model.add(GRU(num_units, go_backwards=True, name='GRU_encoder'))\n",
        "    # output shape of decoder = (batch , num_units)\n",
        "    \n",
        "    ########### INTERMEDIARY ###########\n",
        "    # This adjusts the shape of the Encoder output (2D) to the need of the Decoder (3D input).\n",
        "    # We repeat the 2D vector over sequence_length times to produce the shape (batchsize, seq_length, num_units)\n",
        "    model.add(RepeatVector(output_sequence_length, name='Glue'))\n",
        "    # output shape of glue intermediary step = (batch , seq_length, num_units) compatible with expected input for Decoder GRU  \n",
        "    \n",
        "    ########### DECODER ###########\n",
        "       \n",
        "    model.add(GRU(num_units, return_sequences=True, name='GRU_decoder'))\n",
        "    \n",
        "    model.add(TimeDistributed(Dense(french_vocab_size), name='Dense'))\n",
        "    \n",
        "    model.add(Activation('softmax', name='softmax'))\n",
        "    # output shape of decoder = (batch , french_vocab_size) probability distribution over target vocabulary\n",
        "    \n",
        "    ########### END-TO-END MODEL ###########\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "#tests.test_encdec_model(encdec_model) # commented out to avoid error: english sequences padded to french sequence max length\n",
        "\n",
        "# OPTIONAL: Train and Print prediction(s)\n",
        "\n",
        "# TODO: Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length) # pad input sequence to output sequence length\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))    # reshape for embedding input\n",
        "\n",
        "# Train the neural network\n",
        "enc_dec_model4 = encdec_model4(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "enc_dec_model4.summary()\n",
        "\n",
        "enc_dec_model4.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=30, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qmzW_4Vrmln",
        "outputId": "7d7bdc30-1055-4c21-b5cd-d0545d152ef4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"enc_dec_model4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Embedding_layer (Embedding)  (None, 21, 256)          51200     \n",
            "                                                                 \n",
            " GRU_encoder (GRU)           (None, 256)               394752    \n",
            "                                                                 \n",
            " Glue (RepeatVector)         (None, 21, 256)           0         \n",
            "                                                                 \n",
            " GRU_decoder (GRU)           (None, 21, 256)           394752    \n",
            "                                                                 \n",
            " Dense (TimeDistributed)     (None, 21, 345)           88665     \n",
            "                                                                 \n",
            " softmax (Activation)        (None, 21, 345)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 929,369\n",
            "Trainable params: 929,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "108/108 [==============================] - 262s 2s/step - loss: 2.9520 - accuracy: 0.4375 - val_loss: 2.1204 - val_accuracy: 0.4908\n",
            "Epoch 2/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 1.8835 - accuracy: 0.5347 - val_loss: 1.6719 - val_accuracy: 0.5724\n",
            "Epoch 3/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 1.5347 - accuracy: 0.6029 - val_loss: 1.4414 - val_accuracy: 0.6227\n",
            "Epoch 4/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 1.3323 - accuracy: 0.6437 - val_loss: 1.2453 - val_accuracy: 0.6626\n",
            "Epoch 5/30\n",
            "108/108 [==============================] - 259s 2s/step - loss: 1.1747 - accuracy: 0.6806 - val_loss: 1.1157 - val_accuracy: 0.6955\n",
            "Epoch 6/30\n",
            "108/108 [==============================] - 259s 2s/step - loss: 1.0488 - accuracy: 0.7101 - val_loss: 1.0029 - val_accuracy: 0.7195\n",
            "Epoch 7/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.9759 - accuracy: 0.7242 - val_loss: 0.9300 - val_accuracy: 0.7350\n",
            "Epoch 8/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.9040 - accuracy: 0.7415 - val_loss: 0.8641 - val_accuracy: 0.7517\n",
            "Epoch 9/30\n",
            "108/108 [==============================] - 259s 2s/step - loss: 0.8330 - accuracy: 0.7584 - val_loss: 0.8052 - val_accuracy: 0.7655\n",
            "Epoch 10/30\n",
            "108/108 [==============================] - 259s 2s/step - loss: 0.7709 - accuracy: 0.7741 - val_loss: 0.7391 - val_accuracy: 0.7833\n",
            "Epoch 11/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.7165 - accuracy: 0.7898 - val_loss: 0.6973 - val_accuracy: 0.7966\n",
            "Epoch 12/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.6629 - accuracy: 0.8064 - val_loss: 0.6421 - val_accuracy: 0.8126\n",
            "Epoch 13/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.6086 - accuracy: 0.8223 - val_loss: 0.5802 - val_accuracy: 0.8299\n",
            "Epoch 14/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.5569 - accuracy: 0.8375 - val_loss: 0.5367 - val_accuracy: 0.8429\n",
            "Epoch 15/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.5091 - accuracy: 0.8520 - val_loss: 0.4914 - val_accuracy: 0.8594\n",
            "Epoch 16/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.4638 - accuracy: 0.8666 - val_loss: 0.4513 - val_accuracy: 0.8716\n",
            "Epoch 17/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.4263 - accuracy: 0.8778 - val_loss: 0.4072 - val_accuracy: 0.8842\n",
            "Epoch 18/30\n",
            "108/108 [==============================] - 259s 2s/step - loss: 0.3886 - accuracy: 0.8890 - val_loss: 0.3781 - val_accuracy: 0.8926\n",
            "Epoch 19/30\n",
            "108/108 [==============================] - 259s 2s/step - loss: 0.3589 - accuracy: 0.8979 - val_loss: 0.3559 - val_accuracy: 0.8992\n",
            "Epoch 20/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.3342 - accuracy: 0.9058 - val_loss: 0.3361 - val_accuracy: 0.9059\n",
            "Epoch 21/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.3105 - accuracy: 0.9131 - val_loss: 0.3133 - val_accuracy: 0.9127\n",
            "Epoch 22/30\n",
            "108/108 [==============================] - 257s 2s/step - loss: 0.2785 - accuracy: 0.9229 - val_loss: 0.2934 - val_accuracy: 0.9205\n",
            "Epoch 23/30\n",
            "108/108 [==============================] - 257s 2s/step - loss: 0.2596 - accuracy: 0.9287 - val_loss: 0.2635 - val_accuracy: 0.9262\n",
            "Epoch 24/30\n",
            "108/108 [==============================] - 257s 2s/step - loss: 0.2319 - accuracy: 0.9362 - val_loss: 0.2306 - val_accuracy: 0.9369\n",
            "Epoch 25/30\n",
            "108/108 [==============================] - 257s 2s/step - loss: 0.2119 - accuracy: 0.9425 - val_loss: 0.2300 - val_accuracy: 0.9360\n",
            "Epoch 26/30\n",
            "108/108 [==============================] - 257s 2s/step - loss: 0.2020 - accuracy: 0.9447 - val_loss: 0.2036 - val_accuracy: 0.9428\n",
            "Epoch 27/30\n",
            "108/108 [==============================] - 258s 2s/step - loss: 0.1839 - accuracy: 0.9491 - val_loss: 0.1835 - val_accuracy: 0.9496\n",
            "Epoch 28/30\n",
            "108/108 [==============================] - 257s 2s/step - loss: 0.1670 - accuracy: 0.9541 - val_loss: 0.1835 - val_accuracy: 0.9495\n",
            "Epoch 29/30\n",
            "108/108 [==============================] - 257s 2s/step - loss: 0.1600 - accuracy: 0.9556 - val_loss: 0.1705 - val_accuracy: 0.9527\n",
            "Epoch 30/30\n",
            "108/108 [==============================] - 257s 2s/step - loss: 0.1433 - accuracy: 0.9604 - val_loss: 0.1621 - val_accuracy: 0.9557\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa7344a13d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print('---- Original ----')\n",
        "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n",
        "print()\n",
        "translate(enc_dec_model4.predict(tmp_x[:1]), preproc_french_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3-AE_GyL1wK",
        "outputId": "f8e9a270-497d-49d5-c1e1-f0919bf48567"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Original ----\n",
            "new jersey is sometimes quiet during autumn and it is snowy in april\n",
            "\n",
            "---- Gold standard ----\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
            "\n",
            "---- Prediction ----\n",
            "\u001b[0;30;0m new\u001b[0;30;0m jersey\u001b[0;30;0m est\u001b[0;30;0m parfois\u001b[0;30;0m calme\u001b[0;31;47m au\u001b[0;31;47m cours\u001b[0;30;0m automne\u001b[0;30;0m et\u001b[0;30;0m il\u001b[0;30;0m est\u001b[0;31;47m il\u001b[0;30;0m en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Model 5: Custom (IMPLEMENTATION)\n",
        "\n",
        "Creating a model that incorporates embedding and a bidirectional rnn into one model.\n",
        "Inputs/Outputs shape Customl RNN\n",
        "\n",
        "    Embedding requires input shape (batchsize, input_length) and outputs (batchsize, input_length, embedded_dim)\n",
        "    this shape is OK for input to LSTM (3D)\n",
        "    LSTM or GRU Input shape (batchsize, timesteps, embedded_dim). Return_sequence activated to return output at each timestep\n",
        "    output shape Bidir-LSTM (None, timesteps = sequence_length, 2 x LSTM num_units) because both outputs are concatenated.\n",
        "    Use of TimeDistributed wrapper over Dense(target_vocab_size) to process each timestep\n",
        "    for each time step, Dense outputs a probability distribution over target_vocab to predict next word\n",
        "\n"
      ],
      "metadata": {
        "id": "WvtBhahmMOX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    \n",
        "    learning_rate = 6e-3\n",
        "    embedding_size = 256\n",
        "    units = 256\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    ########### ENCODER ###########\n",
        "    \n",
        "    model.add(Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
        "                           input_length= input_shape[1], name=\"Embedding_layer\"))\n",
        "    model.add(Bidirectional(LSTM(units, return_sequences=False), name='Bi_LSTM_encoder'))\n",
        "    \n",
        "    ########### INTERMEDIARY ###########\n",
        "    \n",
        "    model.add(RepeatVector(output_sequence_length, name='Glue'))\n",
        "    \n",
        "    ########### DECODER ###########\n",
        "    \n",
        "    model.add(LSTM(units, return_sequences=True, name='LSTM_decoder'))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'), name='Dense'))\n",
        "    \n",
        "    ########### END-TO-END MODEL ###########\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "#tests.test_model_final(model_final)\n",
        "\n",
        "# TODO: Train the final model\n",
        "\n",
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length) # pad input sequence to output sequence length\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))    # reshape for embedding input\n",
        "\n",
        "# Train the neural network\n",
        "final_model = model_final(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "final_model.summary()\n",
        "\n",
        "final_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
        "\n",
        "print('Final Model Loaded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7euuz_f8MFcw",
        "outputId": "003e2aa5-cfbc-43b3-bba9-0146600e604c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Embedding_layer (Embedding)  (None, 21, 256)          51200     \n",
            "                                                                 \n",
            " Bi_LSTM_encoder (Bidirectio  (None, 512)              1050624   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " Glue (RepeatVector)         (None, 21, 512)           0         \n",
            "                                                                 \n",
            " LSTM_decoder (LSTM)         (None, 21, 256)           787456    \n",
            "                                                                 \n",
            " Dense (TimeDistributed)     (None, 21, 345)           88665     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,977,945\n",
            "Trainable params: 1,977,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "108/108 [==============================] - 635s 6s/step - loss: 2.4783 - accuracy: 0.4768 - val_loss: 1.7487 - val_accuracy: 0.5673\n",
            "Epoch 2/10\n",
            "108/108 [==============================] - 629s 6s/step - loss: 1.4731 - accuracy: 0.6160 - val_loss: 1.2329 - val_accuracy: 0.6637\n",
            "Epoch 3/10\n",
            "108/108 [==============================] - 640s 6s/step - loss: 1.1039 - accuracy: 0.6912 - val_loss: 0.9483 - val_accuracy: 0.7290\n",
            "Epoch 4/10\n",
            "108/108 [==============================] - 645s 6s/step - loss: 0.8484 - accuracy: 0.7538 - val_loss: 0.7140 - val_accuracy: 0.7925\n",
            "Epoch 5/10\n",
            "108/108 [==============================] - 643s 6s/step - loss: 0.6135 - accuracy: 0.8175 - val_loss: 0.5192 - val_accuracy: 0.8451\n",
            "Epoch 6/10\n",
            "108/108 [==============================] - 614s 6s/step - loss: 0.4400 - accuracy: 0.8681 - val_loss: 0.3789 - val_accuracy: 0.8884\n",
            "Epoch 7/10\n",
            "108/108 [==============================] - 619s 6s/step - loss: 0.3613 - accuracy: 0.8949 - val_loss: 0.3533 - val_accuracy: 0.8956\n",
            "Epoch 8/10\n",
            "108/108 [==============================] - 625s 6s/step - loss: 0.2722 - accuracy: 0.9225 - val_loss: 0.2480 - val_accuracy: 0.9313\n",
            "Epoch 9/10\n",
            "108/108 [==============================] - 626s 6s/step - loss: 0.2146 - accuracy: 0.9427 - val_loss: 0.1961 - val_accuracy: 0.9497\n",
            "Epoch 10/10\n",
            "108/108 [==============================] - 617s 6s/step - loss: 0.1618 - accuracy: 0.9597 - val_loss: 0.1552 - val_accuracy: 0.9618\n",
            "Final Model Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('---- Original ----')\n",
        "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n",
        "print()\n",
        "translate(final_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsfsjVkkeHn_",
        "outputId": "b2805e3e-10de-48b7-f1d1-7dae4f6a2185"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Original ----\n",
            "new jersey is sometimes quiet during autumn and it is snowy in april\n",
            "\n",
            "---- Gold standard ----\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
            "\n",
            "---- Prediction ----\n",
            "\u001b[0;30;0m new\u001b[0;30;0m jersey\u001b[0;30;0m est\u001b[0;30;0m parfois\u001b[0;30;0m calme\u001b[0;30;0m pendant\u001b[0;30;0m l'\u001b[0;30;0m automne\u001b[0;30;0m et\u001b[0;30;0m il\u001b[0;30;0m est\u001b[0;30;0m neigeux\u001b[0;30;0m en\u001b[0;30;0m avril\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Prediction (IMPLEMENTATION)\n",
        "\n",
        "    the objective is to reach a minimum of 95% validation accuracy so that to have meaningful predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "eW7iQ579eNVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_predictions(x, y, x_tk, y_tk):\n",
        "    \"\"\"\n",
        "    Gets predictions using the final model\n",
        "    :param x: Preprocessed English data\n",
        "    :param y: Preprocessed French data\n",
        "    :param x_tk: English tokenizer\n",
        "    :param y_tk: French tokenizer\n",
        "    \"\"\"\n",
        "    # align padded english sequence to the length of french padded length\n",
        "    x = pad_sequences(x)     \n",
        "    \n",
        "    # Instantiate the best model\n",
        "\n",
        "    model = model_final(x.shape,\n",
        "                        preproc_french_sentences.shape[1],\n",
        "                        len(english_tokenizer.word_index)+1,\n",
        "                        len(french_tokenizer.word_index)+1)\n",
        "    \n",
        "    model.summary()\n",
        "                                 \n",
        "    # train the model - Reach a minimum of 94% accuracy so that to have meaningful predictions\n",
        "    model.fit(x, y, batch_size=1024, epochs=10, validation_split=0.2)\n",
        "\n",
        "    \n",
        "    ## DON'T EDIT ANYTHING BELOW THIS LINE\n",
        "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
        "    y_id_to_word[0] = '<PAD>'\n",
        "\n",
        "    sentence = 'he saw a old yellow truck'\n",
        "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
        "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
        "    sentences = np.array([sentence[0], x[0]])\n",
        "    predictions = model.predict(sentences, len(sentences))\n",
        "\n",
        "    print('Sample 1:')\n",
        "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
        "    print('Il a vu un vieux camion jaune')\n",
        "    print('Sample 2:')\n",
        "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
        "    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))\n",
        "\n",
        "final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf07L5BdeOtr",
        "outputId": "e3db5b88-b429-41c8-fdf8-6fa23c365dc9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Embedding_layer (Embedding)  (None, 15, 256)          51200     \n",
            "                                                                 \n",
            " Bi_LSTM_encoder (Bidirectio  (None, 512)              1050624   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " Glue (RepeatVector)         (None, 21, 512)           0         \n",
            "                                                                 \n",
            " LSTM_decoder (LSTM)         (None, 21, 256)           787456    \n",
            "                                                                 \n",
            " Dense (TimeDistributed)     (None, 21, 345)           88665     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,977,945\n",
            "Trainable params: 1,977,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "108/108 [==============================] - 563s 5s/step - loss: 2.5496 - accuracy: 0.4702 - val_loss: 1.8990 - val_accuracy: 0.5384\n",
            "Epoch 2/10\n",
            "108/108 [==============================] - 530s 5s/step - loss: 1.5803 - accuracy: 0.5910 - val_loss: 1.3521 - val_accuracy: 0.6390\n",
            "Epoch 3/10\n",
            "108/108 [==============================] - 517s 5s/step - loss: 1.1305 - accuracy: 0.6885 - val_loss: 1.0059 - val_accuracy: 0.7114\n",
            "Epoch 4/10\n",
            "108/108 [==============================] - 525s 5s/step - loss: 0.8447 - accuracy: 0.7550 - val_loss: 0.7095 - val_accuracy: 0.7908\n",
            "Epoch 5/10\n",
            "108/108 [==============================] - 527s 5s/step - loss: 0.5938 - accuracy: 0.8253 - val_loss: 0.4974 - val_accuracy: 0.8540\n",
            "Epoch 6/10\n",
            "108/108 [==============================] - 531s 5s/step - loss: 0.3977 - accuracy: 0.8840 - val_loss: 0.3511 - val_accuracy: 0.8996\n",
            "Epoch 7/10\n",
            "108/108 [==============================] - 527s 5s/step - loss: 0.2593 - accuracy: 0.9297 - val_loss: 0.2136 - val_accuracy: 0.9453\n",
            "Epoch 8/10\n",
            "108/108 [==============================] - 523s 5s/step - loss: 0.1752 - accuracy: 0.9549 - val_loss: 0.1658 - val_accuracy: 0.9571\n",
            "Epoch 9/10\n",
            "108/108 [==============================] - 516s 5s/step - loss: 0.1356 - accuracy: 0.9641 - val_loss: 0.1344 - val_accuracy: 0.9648\n",
            "Epoch 10/10\n",
            "108/108 [==============================] - 517s 5s/step - loss: 0.1088 - accuracy: 0.9707 - val_loss: 0.1107 - val_accuracy: 0.9704\n",
            "Sample 1:\n",
            "il a vu un vieux camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Il a vu un vieux camion jaune\n",
            "Sample 2:\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    }
  ]
}